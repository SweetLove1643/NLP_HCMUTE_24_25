{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model, classfication bằng MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediecting class of d5:  B\n",
      "Probability of d5 in each class:  [[0.29175335 0.70824665]]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "\n",
    "#train data\n",
    "#sử dụng bag of word để tạo d1,d2,...\n",
    "d1 =[2, 1, 1, 0, 0, 0, 0, 0, 0]\n",
    "d2 =[1, 1, 0, 1, 1, 0, 0, 0, 0]\n",
    "d3 =[0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
    "d4 =[0, 1, 0, 0, 0, 0, 1, 1, 1]\n",
    "train_data = np.array([d1, d2, d3, d4])\n",
    "label = np.array(['B', 'B', 'B', 'N'])\n",
    "#test data\n",
    "d5 = np.array([[2, 0, 0, 1, 0, 0, 0, 1, 0]])\n",
    "d6 = np.array([[0, 1, 0, 0, 0, 0, 0, 1, 1]])\n",
    "# call MultinomialNB\n",
    "model = MultinomialNB()\n",
    "#training   \n",
    "model.fit(train_data, label)\n",
    "\n",
    "#test\n",
    "print('Prediecting class of d5: ', str(model.predict(d5)[0]))\n",
    "print('Probability of d5 in each class: ', model.predict_proba(d6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def BagofWord(input):\n",
    "    sentences = []\n",
    "    input = input.split('.')\n",
    "\n",
    "    for senten in input:\n",
    "        sen = senten.split(',')\n",
    "        for i in sen:\n",
    "            sentences.append(i)\n",
    "    bagofword = CountVectorizer()\n",
    "    result = bagofword.fit_transform(sentences)\n",
    "    index_token = bagofword.get_feature_names_out()\n",
    "    return result.toarray(), index_token, sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Áp dụng thêm bag og word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediecting class of d5:  B\n",
      "Probability of d5 in each class:  [[0.9785359 0.0214641]]\n",
      "Prediecting class of d5:  B\n",
      "Probability of d5 in each class:  [[0.78796179 0.21203821]]\n"
     ]
    }
   ],
   "source": [
    "matrix, tokens, sentence = BagofWord(\"a little less extreme than in the past , with longer exposition sequences between them , and with fewer gags to break the tedium .\")\n",
    "label = np.array(['B', 'N', 'N', 'N'])\n",
    "\n",
    "#test\n",
    "d_test = np.array([[0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0]])\n",
    "d6 = np.array([[0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1]])\n",
    "\n",
    "model = MultinomialNB()\n",
    "#training\n",
    "model.fit(matrix, label)\n",
    "\n",
    "#test\n",
    "print('Prediecting class of d5: ', str(model.predict(d_test)[0]))\n",
    "print('Probability of d5 in each class: ', model.predict_proba(d_test))\n",
    "print('Prediecting class of d5: ', str(model.predict(d6)[0]))\n",
    "print('Probability of d5 in each class: ', model.predict_proba(d6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sử dụng Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediecting class of d5:  B\n",
      "Probability of d5 in each class:  [[0.54406889 0.45593111]]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "#train data\n",
    "#sử dụng bag of word để tạo d1,d2,...\n",
    "d1 =[2, 1, 1, 0, 0, 0, 0, 0, 0]\n",
    "d2 =[1, 1, 0, 1, 1, 0, 0, 0, 0]\n",
    "d3 =[0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
    "d4 =[0, 1, 0, 0, 0, 0, 1, 1, 1]\n",
    "train_data = np.array([d1, d2, d3, d4])\n",
    "label = np.array(['B', 'B', 'B', 'N'])\n",
    "#test data\n",
    "d5 = np.array([[2, 0, 0, 1, 0, 0, 0, 1, 0]])\n",
    "d6 = np.array([[0, 1, 0, 0, 0, 0, 0, 1, 1]])\n",
    "# call MultinomialNB\n",
    "model = LogisticRegression()\n",
    "#training\n",
    "model.fit(train_data, label)\n",
    "\n",
    "#test\n",
    "print('Prediecting class of d5: ', str(model.predict(d5)[0]))\n",
    "print('Probability of d5 in each class: ', model.predict_proba(d6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediecting class of d5:  B\n",
      "Probability of d5 in each class:  [[0.61074157 0.38925843]]\n",
      "Prediecting class of d5:  N\n",
      "Probability of d5 in each class:  [[0.35968349 0.64031651]]\n"
     ]
    }
   ],
   "source": [
    "matrix, tokens, sentence = BagofWord(\"a little less extreme than in the past , with longer exposition sequences between them , and with fewer gags to break the tedium .\")\n",
    "label = np.array(['B', 'N', 'N', 'N'])\n",
    "\n",
    "#test\n",
    "d_test = np.array([[0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0]])\n",
    "d6 = np.array([[0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1]])\n",
    "\n",
    "model = LogisticRegression()\n",
    "#training\n",
    "model.fit(matrix, label)\n",
    "\n",
    "#test\n",
    "print('Prediecting class of d5: ', str(model.predict(d_test)[0]))\n",
    "print('Probability of d5 in each class: ', model.predict_proba(d_test))\n",
    "print('Prediecting class of d5: ', str(model.predict(d6)[0]))\n",
    "print('Probability of d5 in each class: ', model.predict_proba(d6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90       129\n",
      "           1       0.77      0.83      0.80       162\n",
      "           2       0.80      0.84      0.82       128\n",
      "           3       0.80      0.80      0.80       163\n",
      "           4       0.93      0.85      0.89       167\n",
      "           5       0.85      0.87      0.86       142\n",
      "           6       0.82      0.87      0.84       150\n",
      "           7       0.84      0.88      0.86       150\n",
      "           8       0.95      0.96      0.95       146\n",
      "           9       0.96      0.97      0.96       153\n",
      "          10       0.97      0.96      0.96       157\n",
      "          11       0.98      0.91      0.94       137\n",
      "          12       0.83      0.87      0.85       149\n",
      "          13       0.95      0.95      0.95       133\n",
      "          14       0.95      0.96      0.95       151\n",
      "          15       0.79      0.96      0.87       118\n",
      "          16       0.94      0.94      0.94       150\n",
      "          17       0.98      0.99      0.98       129\n",
      "          18       0.94      0.88      0.91       117\n",
      "          19       0.90      0.61      0.73        98\n",
      "\n",
      "    accuracy                           0.89      2829\n",
      "   macro avg       0.89      0.89      0.89      2829\n",
      "weighted avg       0.89      0.89      0.89      2829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# load dataset\n",
    "dataset = fetch_20newsgroups()\n",
    "x, y = dataset.data, dataset.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=45)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "x_train = vectorizer.fit_transform(x_train)\n",
    "x_test = vectorizer.transform(x_test)\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93       129\n",
      "           1       0.76      0.82      0.79       162\n",
      "           2       0.81      0.82      0.82       128\n",
      "           3       0.79      0.77      0.78       163\n",
      "           4       0.86      0.84      0.85       167\n",
      "           5       0.84      0.82      0.83       142\n",
      "           6       0.84      0.87      0.85       150\n",
      "           7       0.83      0.84      0.84       150\n",
      "           8       0.94      0.93      0.93       146\n",
      "           9       0.91      0.94      0.93       153\n",
      "          10       0.96      0.93      0.94       157\n",
      "          11       0.96      0.93      0.94       137\n",
      "          12       0.80      0.83      0.81       149\n",
      "          13       0.93      0.94      0.93       133\n",
      "          14       0.97      0.95      0.96       151\n",
      "          15       0.78      0.97      0.87       118\n",
      "          16       0.94      0.95      0.94       150\n",
      "          17       0.99      0.96      0.98       129\n",
      "          18       0.93      0.85      0.89       117\n",
      "          19       0.91      0.73      0.81        98\n",
      "\n",
      "    accuracy                           0.88      2829\n",
      "   macro avg       0.89      0.88      0.88      2829\n",
      "weighted avg       0.88      0.88      0.88      2829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# load dataset\n",
    "dataset = fetch_20newsgroups()\n",
    "x, y = dataset.data, dataset.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=45)\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "x_train = vectorizer.fit_transform(x_train)\n",
    "x_test = vectorizer.transform(x_test)\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93       129\n",
      "           1       0.76      0.82      0.79       162\n",
      "           2       0.81      0.82      0.82       128\n",
      "           3       0.79      0.77      0.78       163\n",
      "           4       0.86      0.84      0.85       167\n",
      "           5       0.84      0.82      0.83       142\n",
      "           6       0.84      0.87      0.85       150\n",
      "           7       0.83      0.84      0.84       150\n",
      "           8       0.94      0.93      0.93       146\n",
      "           9       0.91      0.94      0.93       153\n",
      "          10       0.96      0.93      0.94       157\n",
      "          11       0.96      0.93      0.94       137\n",
      "          12       0.80      0.83      0.81       149\n",
      "          13       0.93      0.94      0.93       133\n",
      "          14       0.97      0.95      0.96       151\n",
      "          15       0.78      0.97      0.87       118\n",
      "          16       0.94      0.95      0.94       150\n",
      "          17       0.99      0.96      0.98       129\n",
      "          18       0.93      0.85      0.89       117\n",
      "          19       0.91      0.73      0.81        98\n",
      "\n",
      "    accuracy                           0.88      2829\n",
      "   macro avg       0.89      0.88      0.88      2829\n",
      "weighted avg       0.88      0.88      0.88      2829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# load dataset\n",
    "dataset = fetch_20newsgroups()\n",
    "x, y = dataset.data, dataset.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=45)\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", ngram_range=(1, 1))\n",
    "x_train = vectorizer.fit_transform(x_train)\n",
    "x_test = vectorizer.transform(x_test)\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m x, y = dataset.data, dataset.target\n\u001b[32m     11\u001b[39m x = [text[:\u001b[32m500\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m y = \u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     13\u001b[39m x = np.array(x).reshape(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m     16\u001b[39m x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=\u001b[32m0.25\u001b[39m, random_state=\u001b[32m45\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     10\u001b[39m x, y = dataset.data, dataset.target\n\u001b[32m     11\u001b[39m x = [text[:\u001b[32m500\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m y = [\u001b[43mtext\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m y]\n\u001b[32m     13\u001b[39m x = np.array(x).reshape(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m     16\u001b[39m x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=\u001b[32m0.25\u001b[39m, random_state=\u001b[32m45\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "# load dataset\n",
    "dataset = fetch_20newsgroups()\n",
    "x, y = dataset.data, dataset.target\n",
    "x = np.array(x).reshape(-1, 1)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=45)\n",
    "\n",
    "vectorizer = OneHotEncoder()\n",
    "x_train = vectorizer.fit_transform(x_train)\n",
    "x_test = vectorizer.transform(x_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tìm hiểu SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       129\n",
      "           1       0.00      0.00      0.00       162\n",
      "           2       0.14      0.14      0.14       128\n",
      "           3       0.19      0.02      0.03       163\n",
      "           4       0.09      0.02      0.04       167\n",
      "           5       0.00      0.00      0.00       142\n",
      "           6       0.10      0.01      0.02       150\n",
      "           7       0.04      0.01      0.01       150\n",
      "           8       0.00      0.00      0.00       146\n",
      "           9       0.00      0.00      0.00       153\n",
      "          10       0.07      0.05      0.06       157\n",
      "          11       0.05      0.70      0.09       137\n",
      "          12       0.09      0.09      0.09       149\n",
      "          13       0.00      0.00      0.00       133\n",
      "          14       0.05      0.11      0.07       151\n",
      "          15       0.00      0.00      0.00       118\n",
      "          16       0.00      0.00      0.00       150\n",
      "          17       0.00      0.00      0.00       129\n",
      "          18       0.00      0.00      0.00       117\n",
      "          19       0.00      0.00      0.00        98\n",
      "\n",
      "    accuracy                           0.06      2829\n",
      "   macro avg       0.04      0.06      0.03      2829\n",
      "weighted avg       0.04      0.06      0.03      2829\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Documents\\Study\\Projects\\HK6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Admin\\Documents\\Study\\Projects\\HK6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Admin\\Documents\\Study\\Projects\\HK6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "# Tải dữ liệu\n",
    "dataset = fetch_20newsgroups(remove=('headers', 'footers', 'quotes'))\n",
    "x, y = dataset.data, dataset.target\n",
    "x = [text[:500] for text in x]\n",
    "\n",
    "# Trích xuất đặc trưng\n",
    "def extract_keyword_features(texts, keywords):\n",
    "    return np.array([[1 if kw in text.lower() else 0 for kw in keywords] for text in texts])\n",
    "\n",
    "keywords = [\"good\", \"bad\", \"great\", \"problem\", \"like\"]\n",
    "x_features = extract_keyword_features(x, keywords)\n",
    "\n",
    "# Chia dữ liệu\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_features, y, test_size=0.25, random_state=45)\n",
    "\n",
    "# Huấn luyện SVM\n",
    "svm = SVC(kernel='rbf', C=1.0, gamma='scale')  # Dùng kernel RBF\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "# Dự đoán và đánh giá\n",
    "pred = svm.predict(x_test)\n",
    "print(metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Báo cáo phân loại:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.00      0.00      0.00         0\n",
      "           P       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.50      0.25      0.33         2\n",
      "weighted avg       1.00      0.50      0.67         2\n",
      "\n",
      "\n",
      "Dữ liệu gốc và nhãn:\n",
      "Text: Tôi rất thích sản phẩm này, nó tuyệt vời! | Label: P\n",
      "Text: Dịch vụ quá tệ, tôi không hài lòng chút nào. | Label: P\n",
      "Text: Mọi thứ ổn, không có gì đặc biệt. | Label: N\n",
      "Text: Chất lượng kém, tôi sẽ không mua lại. | Label: P\n",
      "Text: Thật sự ấn tượng với tốc độ giao hàng. | Label: P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Documents\\Study\\Projects\\HK6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Admin\\Documents\\Study\\Projects\\HK6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Admin\\Documents\\Study\\Projects\\HK6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "texts = [\n",
    "    \"Tôi rất thích sản phẩm này, nó tuyệt vời!\",\n",
    "    \"Dịch vụ quá tệ, tôi không hài lòng chút nào.\",\n",
    "    \"Mọi thứ ổn, không có gì đặc biệt.\",\n",
    "    \"Chất lượng kém, tôi sẽ không mua lại.\",\n",
    "    \"Thật sự ấn tượng với tốc độ giao hàng.\"\n",
    "]\n",
    "\n",
    "# Gán nhãn ngẫu nhiên \"N\" hoặc \"P\"\n",
    "labels = np.random.choice([\"N\", \"P\"], size=len(texts))\n",
    "\n",
    "# Trích xuất đặc trưng từ văn bản\n",
    "def extract_keyword_features(texts, keywords):\n",
    "    return np.array([[1 if kw in text.lower() else 0 for kw in keywords] for text in texts])\n",
    "\n",
    "keywords = [\"tốt\", \"tệ\", \"thích\", \"kém\", \"tuyệt vời\"]\n",
    "x_features = extract_keyword_features(texts, keywords)\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và kiểm tra\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Huấn luyện SVM\n",
    "svm = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "# Dự đoán và đánh giá\n",
    "pred = svm.predict(x_test)\n",
    "print(\"Báo cáo phân loại:\")\n",
    "print(metrics.classification_report(y_test, pred))\n",
    "\n",
    "# In dữ liệu để kiểm tra\n",
    "print(\"\\nDữ liệu gốc và nhãn:\")\n",
    "for text, label in zip(texts, labels):\n",
    "    print(f\"Text: {text} | Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
