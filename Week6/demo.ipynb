{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The size of the vector increases with the size of the vocabulary limiting the vocabulary to n number of the most frequent words', ' It does not capture the similarity between different words that mean the same thing']\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 3\n",
      "  3 1 1 1 0 0 0 0 0 2 2 2 0 0 0 6 1 1 0 0 0 0 2 2 1 1 2 1 1 0 1 1 1 1 1 1\n",
      "  2 1 1 1 1 1 1 1 1 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 0\n",
      "  0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 2 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 1 1 1]]\n",
      "{'the': 51, 'size': 45, 'of': 35, 'vector': 69, 'increases': 14, 'with': 77, 'vocabulary': 72, 'limiting': 20, 'to': 66, 'number': 32, 'most': 26, 'frequent': 12, 'words': 80, 'the size': 58, 'size of': 46, 'of the': 36, 'the vector': 60, 'vector increases': 70, 'increases with': 15, 'with the': 78, 'the vocabulary': 62, 'vocabulary limiting': 73, 'limiting the': 21, 'vocabulary to': 75, 'to number': 67, 'number of': 33, 'the most': 52, 'most frequent': 27, 'frequent words': 13, 'the size of': 59, 'size of the': 47, 'of the vector': 38, 'the vector increases': 61, 'vector increases with': 71, 'increases with the': 16, 'with the size': 79, 'of the vocabulary': 39, 'the vocabulary limiting': 63, 'vocabulary limiting the': 74, 'limiting the vocabulary': 22, 'the vocabulary to': 64, 'vocabulary to number': 76, 'to number of': 68, 'number of the': 34, 'of the most': 37, 'the most frequent': 53, 'most frequent words': 28, 'it': 17, 'does': 9, 'not': 29, 'capture': 3, 'similarity': 42, 'between': 0, 'different': 6, 'that': 48, 'mean': 23, 'same': 40, 'thing': 65, 'it does': 18, 'does not': 10, 'not capture': 30, 'capture the': 4, 'the similarity': 56, 'similarity between': 43, 'between different': 1, 'different words': 7, 'words that': 81, 'that mean': 49, 'mean the': 24, 'the same': 54, 'same thing': 41, 'it does not': 19, 'does not capture': 11, 'not capture the': 31, 'capture the similarity': 5, 'the similarity between': 57, 'similarity between different': 44, 'between different words': 2, 'different words that': 8, 'words that mean': 82, 'that mean the': 50, 'mean the same': 25, 'the same thing': 55}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "\n",
    "count_vect = CountVectorizer(ngram_range=(1,3))\n",
    "\n",
    "processed_docs =\"The size of the vector increases with the size of the vocabulary limiting the vocabulary to n number of the most frequent words. It does not capture the similarity between different words that mean the same thing.\"\n",
    "\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "# doc = nlp(processed_docs)\n",
    "doc = processed_docs.split(\".\")\n",
    "for sentence in doc:\n",
    "    if sentence == \"\":\n",
    "        doc.remove(sentence)\n",
    "    \n",
    "print(doc)\n",
    "bow_rep = count_vect.fit_transform(doc)\n",
    "result = bow_rep.toarray()\n",
    "print(result)\n",
    "print(count_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.7676916e-03  8.1671821e-03  1.2849364e-03  5.1022586e-03\n",
      "  1.4085056e-03 -6.4544259e-03 -1.4230723e-03  6.4478228e-03\n",
      " -4.6218480e-03 -3.9940262e-03  4.9252524e-03  2.7100104e-03\n",
      " -1.8444083e-03 -2.8796406e-03  6.0135950e-03 -5.7166847e-03\n",
      " -3.2385804e-03 -6.4893644e-03 -4.2386395e-03 -8.5854419e-03\n",
      " -4.4703041e-03 -8.5058585e-03  1.4084366e-03 -8.6221155e-03\n",
      " -9.9172154e-03 -8.1996573e-03 -6.7751436e-03  6.6783638e-03\n",
      "  3.7833457e-03  3.5561304e-04 -2.9567878e-03 -7.4304333e-03\n",
      "  5.3576293e-04  5.0182547e-04  1.9421420e-04  8.5456460e-04\n",
      "  7.8479061e-04 -6.5370543e-05 -8.0065671e-03 -5.8737486e-03\n",
      " -8.3813835e-03 -1.3112477e-03  1.8189856e-03  7.4171438e-03\n",
      " -1.9627414e-03 -2.3281348e-03  9.4858939e-03  8.1656821e-05\n",
      " -2.4043033e-03  8.6044054e-03  2.6853399e-03 -5.3449101e-03\n",
      "  6.5908977e-03  4.5077903e-03 -7.0542665e-03 -3.2239893e-04\n",
      "  8.3392562e-04  5.7473914e-03 -1.7153554e-03 -2.8077548e-03\n",
      "  1.7476290e-03  8.4463519e-04  1.1969601e-03 -2.6338629e-03\n",
      " -5.9894482e-03  7.3246155e-03  7.5838249e-03  8.3005531e-03\n",
      " -8.6040339e-03  2.6355188e-03 -3.5622583e-03  9.6224938e-03\n",
      "  2.9078664e-03  4.6430938e-03  2.3819499e-03  6.6074980e-03\n",
      " -5.7442938e-03  7.8897774e-03 -2.4141413e-03 -4.5643416e-03\n",
      " -2.0622278e-03  9.7303996e-03 -6.8553663e-03 -2.1905124e-03\n",
      "  7.0031467e-03 -5.6547618e-05 -6.2941718e-03 -6.3938266e-03\n",
      "  8.9414455e-03  6.4319908e-03  4.7730748e-03 -3.2614353e-03\n",
      " -9.2686284e-03  3.7875534e-03  7.1655102e-03 -5.6294971e-03\n",
      " -7.8649037e-03 -2.9714247e-03 -4.9276603e-03 -2.3181885e-03]\n",
      "Words most similar to 'friend': [('my', 0.1728028804063797), ('the', 0.1670362502336502), ('one', 0.1113552451133728)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = [\n",
    "    ['my', 'name', 'is', 'the', 'first','cat'],\n",
    "    ['this', 'cat', 'is', 'my', 'second','friend'],\n",
    "    ['and', 'this', 'dog', 'the', 'third','one'],\n",
    "    ['is', 'this', 'my', 'first','document']\n",
    "]\n",
    "\n",
    "\n",
    "model = Word2Vec(sentences, vector_size = 100, window=5, min_count=1)\n",
    "\n",
    "model.train(sentences, total_examples=len(sentences), epochs=10)\n",
    "\n",
    "print(model.wv['friend'])\n",
    "# print(model.wv.most_similar('the'))\n",
    "# similarity = model.wv.similarity('friend', 'cat')\n",
    "# print(f\"Similarity between 'friend' and 'cat': {similarity}\")\n",
    "similar_words = model.wv.most_similar('friend', topn=3)\n",
    "print(f\"Words most similar to 'friend': {similar_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.7279e-01  7.7515e-01 -1.0181e-01 -9.1660e-01  9.0477e-01 -7.0501e-02\n",
      "  -4.7569e-01  4.4608e-01  1.6970e-01  7.2352e-02 -1.6306e-01  8.6852e-01\n",
      "  -7.6634e-01 -1.6103e-02  7.8492e-01  2.9520e-01 -7.4859e-01  2.0990e-01\n",
      "   6.5537e-01 -6.2334e-01 -4.3711e-01  1.1854e+00  4.7519e-01  9.3866e-03\n",
      "   1.1377e+00 -2.4394e+00 -1.5619e+00  4.9001e-01  1.0985e+00 -9.7371e-01\n",
      "   3.4628e+00  1.0408e+00 -6.5138e-01  5.7189e-01 -1.2523e-01  2.6705e-01\n",
      "   1.6373e-01  4.1105e-01  7.5090e-01 -7.7923e-01  3.6380e-02 -2.8609e-01\n",
      "  -7.2365e-01  6.3511e-01  8.9441e-02 -3.0133e-01  3.6518e-01 -7.3367e-01\n",
      "   4.0383e-02  2.6657e-01]\n",
      " [ 2.0957e-01  7.5197e-01 -4.8559e-01  1.3020e-01  6.0071e-01  4.3273e-01\n",
      "  -9.5424e-01 -1.9335e-01 -6.6756e-01 -2.5893e-01  6.6367e-01  1.0509e+00\n",
      "   1.0627e-01 -7.5438e-01  4.5617e-01  3.7878e-01 -4.0237e-01  1.8210e-01\n",
      "  -2.8768e-02  2.4349e-01 -3.5723e-01 -5.5817e-01  1.4103e-01  5.8807e-01\n",
      "   7.6804e-02 -1.9720e+00 -1.4459e+00  8.1884e-02 -2.9207e-01 -6.5623e-01\n",
      "   2.7180e+00 -9.6886e-01 -3.3354e-01 -1.9526e-01  3.3918e-01 -2.4307e-01\n",
      "   2.9058e-01 -3.7178e-01 -3.8133e-01 -2.0901e-01  4.8504e-01  2.0702e-01\n",
      "  -5.7540e-01 -3.2403e-01 -1.9267e-01 -4.3298e-02 -5.7702e-01 -4.7270e-01\n",
      "   4.2171e-01 -1.4112e-01]\n",
      " [ 6.1850e-01  6.4254e-01 -4.6552e-01  3.7570e-01  7.4838e-01  5.3739e-01\n",
      "   2.2239e-03 -6.0577e-01  2.6408e-01  1.1703e-01  4.3722e-01  2.0092e-01\n",
      "  -5.7859e-02 -3.4589e-01  2.1664e-01  5.8573e-01  5.3919e-01  6.9490e-01\n",
      "  -1.5618e-01  5.5830e-02 -6.0515e-01 -2.8997e-01 -2.5594e-02  5.5593e-01\n",
      "   2.5356e-01 -1.9612e+00 -5.1381e-01  6.9096e-01  6.6246e-02 -5.4224e-02\n",
      "   3.7871e+00 -7.7403e-01 -1.2689e-01 -5.1465e-01  6.6705e-02 -3.2933e-01\n",
      "   1.3483e-01  1.9049e-01  1.3812e-01 -2.1503e-01 -1.6573e-02  3.1200e-01\n",
      "  -3.3189e-01 -2.6001e-02 -3.8203e-01  1.9403e-01 -1.2466e-01 -2.7557e-01\n",
      "   3.0899e-01  4.8497e-01]\n",
      " [ 4.1800e-01  2.4968e-01 -4.1242e-01  1.2170e-01  3.4527e-01 -4.4457e-02\n",
      "  -4.9688e-01 -1.7862e-01 -6.6023e-04 -6.5660e-01  2.7843e-01 -1.4767e-01\n",
      "  -5.5677e-01  1.4658e-01 -9.5095e-03  1.1658e-02  1.0204e-01 -1.2792e-01\n",
      "  -8.4430e-01 -1.2181e-01 -1.6801e-02 -3.3279e-01 -1.5520e-01 -2.3131e-01\n",
      "  -1.9181e-01 -1.8823e+00 -7.6746e-01  9.9051e-02 -4.2125e-01 -1.9526e-01\n",
      "   4.0071e+00 -1.8594e-01 -5.2287e-01 -3.1681e-01  5.9213e-04  7.4449e-03\n",
      "   1.7778e-01 -1.5897e-01  1.2041e-02 -5.4223e-02 -2.9871e-01 -1.5749e-01\n",
      "  -3.4758e-01 -4.5637e-02 -4.4251e-01  1.8785e-01  2.7849e-03 -1.8411e-01\n",
      "  -1.1514e-01 -7.8581e-01]\n",
      " [-1.4168e-01  4.1108e-01 -3.1227e-01  1.6633e-01  2.6124e-01  4.5708e-01\n",
      "  -1.2001e+00  1.4923e-02 -2.2779e-01 -1.6937e-01  3.4633e-01 -1.2419e-01\n",
      "  -6.5711e-01  2.9226e-01  6.2407e-01 -5.7916e-01 -3.3947e-01 -2.2046e-01\n",
      "  -1.4832e+00  2.8958e-01  8.1396e-02 -2.1696e-01  5.6613e-03 -5.4199e-02\n",
      "   9.8504e-02 -1.5874e+00 -2.2867e-01 -6.2957e-01 -3.9542e-01 -8.0841e-02\n",
      "   3.5949e+00 -1.6872e-01 -3.9024e-01  2.6912e-02  5.2646e-01 -2.2844e-02\n",
      "   6.3289e-01  6.2702e-01 -2.2171e-01 -4.5045e-01 -1.4998e-01 -2.7723e-01\n",
      "  -4.6658e-01 -4.4268e-01 -4.3691e-01  3.8455e-01  1.3690e-01 -2.5424e-01\n",
      "   1.7821e-02 -1.4890e-01]\n",
      " [ 4.5281e-01 -5.0108e-01 -5.3714e-01 -1.5697e-02  2.2191e-01  5.4602e-01\n",
      "  -6.7301e-01 -6.8910e-01  6.3493e-01 -1.9726e-01  3.3685e-01  7.7350e-01\n",
      "   9.0094e-01  3.8488e-01  3.8367e-01  2.6570e-01 -8.0570e-02  6.1089e-01\n",
      "  -1.2894e+00 -2.2313e-01 -6.1578e-01  2.1697e-01  3.5614e-01  4.4499e-01\n",
      "   6.0885e-01 -1.1633e+00 -1.1579e+00  3.6118e-01  1.0466e-01 -7.8325e-01\n",
      "   1.4352e+00  1.8629e-01 -2.6112e-01  8.3275e-01 -2.3123e-01  3.2481e-01\n",
      "   1.4485e-01 -4.4552e-01  3.3497e-01 -9.5946e-01 -9.7479e-02  4.8138e-01\n",
      "  -4.3352e-01  6.9455e-01  9.1043e-01 -2.8173e-01  4.1637e-01 -1.2609e+00\n",
      "   7.1278e-01  2.3782e-01]]\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "glove_vector = api.load(\"glove-wiki-gigaword-50\")\n",
    "\n",
    "sentences = [\n",
    "    ['my', 'name', 'is', 'the', 'first','cat'],\n",
    "    ['this', 'cat', 'is', 'my', 'second','friend'],\n",
    "    ['and', 'this', 'dog', 'the', 'third','one'],\n",
    "    ['is', 'this', 'my', 'first','document']\n",
    "]\n",
    "\n",
    "vector1 = glove_vector['my', 'name', 'is', 'the', 'first','cat']\n",
    "\n",
    "print(vector1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.0496597e-03  2.4317822e-04 -1.1335124e-03  1.5136275e-03\n",
      "  3.2054950e-04 -2.7889924e-03 -1.0228510e-04  1.1938107e-03\n",
      "  9.3609327e-04 -8.1788970e-04  1.3839683e-03  1.6885719e-04\n",
      "  6.0095050e-04  3.5650139e-03  8.3465845e-04 -1.6599933e-03\n",
      "  5.4694491e-04 -5.2367657e-04  4.2834555e-04 -5.3758442e-04\n",
      "  7.7073462e-04  4.9237069e-04  2.9694239e-04  9.1041700e-04\n",
      " -3.5701832e-03  1.1406810e-03  7.8149591e-05 -1.2577146e-03\n",
      "  2.9973712e-04  8.1732418e-05 -3.4183223e-04  2.6796954e-05\n",
      " -1.7701030e-03  4.1010499e-04  1.2384559e-03  3.9454133e-04\n",
      "  7.4487709e-04 -5.2746636e-04 -9.8432030e-04  1.1149925e-03\n",
      " -8.8882825e-04 -4.6904941e-04  1.7889385e-04  6.2394101e-04\n",
      "  5.3225789e-04  2.3397144e-04 -5.2435184e-04  2.0284327e-03\n",
      " -6.7307125e-04 -7.7381055e-04  9.3273782e-05  1.6708012e-05\n",
      " -1.1557336e-03  1.6117746e-03  2.3809914e-04  1.4120509e-03\n",
      "  2.1848630e-04  1.8349655e-03 -1.7546123e-03 -1.3013523e-04\n",
      "  7.2049914e-04 -8.6034328e-04 -9.1208675e-04  1.8148182e-03\n",
      " -1.1429408e-03  1.0583854e-03  4.9885490e-04 -1.6164988e-03\n",
      "  4.9253221e-04  2.7035768e-03  5.4651656e-04 -1.3025758e-03\n",
      "  8.0322777e-04 -3.0295496e-04 -4.4600232e-04 -1.1379201e-03\n",
      "  9.7742665e-04  6.8770361e-04  4.8365351e-04  1.0259066e-03\n",
      " -4.2098077e-04  1.0593517e-03  2.0378211e-04  6.0752011e-04\n",
      "  2.0113268e-03  1.0211156e-03 -6.1555108e-04 -6.0827163e-04\n",
      "  5.9845031e-04 -9.8452112e-04  1.5445098e-03 -1.4573263e-03\n",
      "  9.2307408e-04 -1.8929295e-03  3.7003825e-05  3.1625021e-03\n",
      "  1.4347994e-03 -5.1896018e-04  1.1684611e-04  1.4423367e-05]\n",
      "[('third', 0.1543603092432022), ('one', 0.09176746755838394), ('is', 0.06848463416099548), ('first', 0.056637540459632874), ('friend', 0.03586330637335777), ('dog', 0.03092409111559391), ('this', 0.021368689835071564), ('name', -0.020129509270191193), ('cat', -0.06837085634469986), ('second', -0.087027408182621)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "sentences = [\n",
    "    ['my', 'name', 'is', 'the', 'first','cat'],\n",
    "    ['this', 'cat', 'is', 'my', 'second','friend'],\n",
    "    ['and', 'this', 'dog', 'the', 'third','one'],\n",
    "    ['is', 'this', 'my', 'first','document']\n",
    "]\n",
    "\n",
    "model = FastText(sentences, vector_size=100, window=5, min_count=1)\n",
    "\n",
    "model.train(sentences, total_examples=len(sentences), epochs=10)\n",
    "\n",
    "print(model.wv['document'])\n",
    "print(model.wv.most_similar('the'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['friend', 'document', 'and', 'my', 'is', 'this', 'dog', 'one', 'second', 'the', 'third', 'cat', 'first', 'name']\n"
     ]
    }
   ],
   "source": [
    "unique_token = set()\n",
    "sentences = [\n",
    "    ['my', 'name', 'is', 'the', 'first','cat'],\n",
    "    ['this', 'cat', 'is', 'my', 'second','friend'],\n",
    "    ['and', 'this', 'dog', 'the', 'third','one'],\n",
    "    ['is', 'this', 'my', 'first','document']\n",
    "]\n",
    "for sentence in sentences:\n",
    "    unique_token.update(sentence)\n",
    "    # for word in sentence:\n",
    "    #     unique_token.add(word)\n",
    "\n",
    "unique_token = list(unique_token)\n",
    "print(unique_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.67714155 -0.15699998  0.7074029   0.40564606 -0.44334555  0.00397286\n",
      "   0.6615859   0.1070006   0.5552436  -0.9976901   0.35113046 -0.15624894\n",
      "   0.95767146 -0.39877266  0.8419982  -0.21155153  0.24476725 -0.43298814\n",
      "   0.3084935  -0.3424728   0.38455164  0.4021533   0.6502714   0.19596659\n",
      "   0.28164628 -0.30627182 -0.29813656  0.84670424  0.90453285  0.56008047\n",
      "  -0.3747237   0.10277051 -0.96338916 -0.06847679  0.66837263 -0.9444749\n",
      "   0.02635764 -0.610016    0.02303107  0.10598574 -0.7897811   0.1350713\n",
      "   0.9654326  -0.46952873 -0.14704387 -0.24778107 -0.9830063   0.16220331\n",
      "  -0.7269781  -0.6230312  -0.53825825 -0.7050665   0.0882479   0.13791046\n",
      "   0.29020965  0.48932314 -0.18435594  0.07935808 -0.09925722 -0.3567494\n",
      "  -0.5454465   0.1795229   0.3713533  -0.7422966  -0.60478497 -0.68892175\n",
      "  -0.06896568 -0.12104703  0.07473963 -0.03060906  0.6576301   0.06581368\n",
      "   0.3221792  -0.6676515  -0.6605665   0.06401106 -0.3253844   0.9986462\n",
      "  -0.00510464 -0.940409   -0.6753526  -0.4839391   0.24018401  0.74183404\n",
      "  -0.6120346  -0.99506235  0.09277164 -0.03368118 -0.96846294  0.20000997\n",
      "   0.07731701 -0.09961072 -0.67785525  0.24248484  0.05334257 -0.03915993\n",
      "  -0.19161843  0.6070199  -0.02516538  0.1545882  -0.01339636 -0.10533813\n",
      "   0.09354659 -0.21899906  0.03881557 -0.24784261 -0.20291075  0.01289458\n",
      "  -0.36171973  0.4679472   0.21523477 -0.21227464  0.10979816 -0.89916396\n",
      "   0.4575941  -0.17193519 -0.94811463 -0.29294425 -0.95784634  0.46654555\n",
      "   0.18358947 -0.01680403  0.8997728   0.6673276   0.11702426  0.07209138\n",
      "   0.67166346 -0.9993183  -0.0750134  -0.00426042  0.37252468 -0.02507835\n",
      "  -0.93441653 -0.89382464  0.35270184  0.9027489   0.01888806  0.9503948\n",
      "  -0.07835148  0.85285664  0.39496547  0.1483618  -0.53474164 -0.31321383\n",
      "   0.11782382  0.13122544 -0.4166174   0.20876908  0.23779221 -0.18433501\n",
      "   0.20359509 -0.10822526  0.5791389  -0.8426209  -0.3704092   0.84282076\n",
      "   0.4846205   0.67236847  0.7411133  -0.10136797 -0.1998755   0.66841745\n",
      "   0.01353244  0.23100033  0.10934746  0.26916197 -0.32057148  0.33651465\n",
      "  -0.69239473  0.37118876  0.19036974 -0.06018701  0.6574492  -0.93079937\n",
      "  -0.1540291   0.19570017  0.96143615  0.5997776   0.08704333 -0.30262122\n",
      "  -0.19127104  0.01108958 -0.8626833   0.9316931  -0.01582588  0.21337733\n",
      "   0.49975467 -0.36369723 -0.7150846  -0.49619752  0.6167162   0.11390144\n",
      "  -0.6908738   0.08097846 -0.36068466 -0.2256804   0.47437814  0.16086069\n",
      "  -0.13318832 -0.3290465   0.02932934  0.8592266   0.7871407   0.5687318\n",
      "  -0.6854279   0.24572293 -0.77569354 -0.2234782   0.03882433  0.15188038\n",
      "  -0.02705665  0.97256064  0.10330524  0.02792577 -0.84619814 -0.95726967\n",
      "  -0.02468341 -0.7516929   0.0578087  -0.48535046  0.1106577   0.5876053\n",
      "  -0.36493564  0.23923928 -0.8854759  -0.57163435  0.19343716 -0.10398202\n",
      "   0.20902795 -0.22404283  0.40628538 -0.57620066 -0.3213138   0.4426484\n",
      "   0.77855635  0.74115366 -0.53243244  0.5319856  -0.11364788  0.6798076\n",
      "  -0.4153419   0.837343   -0.3540089   0.16031425 -0.8019454   0.5745428\n",
      "  -0.6869605   0.47587264  0.0345869  -0.7042517  -0.5082772   0.24653731\n",
      "   0.13684781  0.8321797  -0.284154    0.9338721  -0.39021933 -0.88994807\n",
      "   0.18739776  0.09935937 -0.96016556 -0.5321231   0.13819389 -0.66094744\n",
      "  -0.21946813 -0.17136922 -0.8831134   0.5321564   0.04425727  0.90810883\n",
      "   0.20818327 -0.7132963   0.00280862 -0.7826242  -0.1658255   0.01387353\n",
      "   0.7152695  -0.14945829 -0.89077896  0.30858094  0.3919044   0.2630691\n",
      "   0.79113865  0.94908017  0.9360505   0.9376784   0.75962955  0.6665508\n",
      "  -0.12663786  0.0642314   0.9989265   0.31248423 -0.9911133  -0.855859\n",
      "  -0.30882016  0.22439203 -0.99911195 -0.06261633  0.104103   -0.80416614\n",
      "  -0.57207924  0.93019867  0.87700987 -0.99820507  0.64261246  0.83729666\n",
      "  -0.34200984 -0.23034604 -0.03283172  0.9283588   0.0536851   0.2029329\n",
      "  -0.06723807  0.15809958  0.49383587 -0.6205097   0.67281663  0.59221077\n",
      "  -0.21226679  0.03342127 -0.4057659  -0.81304634 -0.31464136 -0.09200923\n",
      "  -0.44827774 -0.892605   -0.09487919 -0.5251771   0.37254286 -0.0331916\n",
      "   0.06195825 -0.5645161   0.05709056 -0.7175224   0.10278462  0.4199931\n",
      "  -0.84356403 -0.3043685   0.10277246 -0.58769095  0.5739522  -0.89415115\n",
      "   0.9181897  -0.09761199 -0.4130904   0.998225   -0.33596843 -0.6701383\n",
      "   0.02366786  0.03810313 -0.06882739  0.99664706  0.06478456 -0.94219327\n",
      "  -0.28954938 -0.09142227 -0.1879638  -0.19567268  0.9840365  -0.06945363\n",
      "   0.5306463   0.52016354  0.92524046 -0.9666002  -0.3780779  -0.8139205\n",
      "  -0.90591705  0.9011738   0.85171175  0.17403111 -0.2930991  -0.06792465\n",
      "   0.32272384  0.08058549 -0.86051476  0.24748453  0.22278467 -0.11799748\n",
      "   0.7957094  -0.59944403 -0.31306222  0.251332    0.38144457  0.50894666\n",
      "  -0.626632    0.2695824  -0.14986065 -0.02885982 -0.12286329 -0.20493807\n",
      "  -0.9218763  -0.17705981  0.9968082   0.26286212 -0.53886014  0.09981456\n",
      "  -0.04710687 -0.35000172  0.15125962  0.2586592  -0.18932414 -0.6404433\n",
      "  -0.3462896  -0.7502923  -0.957645    0.44432738  0.09542989 -0.1853279\n",
      "   0.94342405  0.00445563  0.09025618 -0.36241207 -0.45024592 -0.01184985\n",
      "   0.25727904 -0.74087864  0.9304088  -0.12913816  0.26356643  0.539998\n",
      "   0.64489573 -0.19548932 -0.4768998  -0.03328703 -0.8190836   0.11721332\n",
      "  -0.86208314  0.89058423 -0.6880588   0.17562951 -0.02254507 -0.3650322\n",
      "   0.99819577  0.12108471  0.33886302  0.00201713  0.57152945 -0.09690983\n",
      "  -0.47454274 -0.26569217  0.03248865  0.6815772  -0.14447683  0.09102475\n",
      "  -0.911058   -0.6045381  -0.40247545 -0.8747436  -0.96735466  0.60987145\n",
      "   0.40287876  0.05000454  0.1942403  -0.43573034 -0.5124814  -0.07485165\n",
      "  -0.05375402 -0.84742254  0.6870349  -0.12943469  0.265619   -0.09530622\n",
      "   0.3092778  -0.671733    0.7968577   0.7447144   0.3013575   0.05141056\n",
      "  -0.539281    0.5898442  -0.5658687   0.5729573  -0.0560586   0.9989611\n",
      "  -0.20110032 -0.52333957  0.54176533  0.3835608  -0.00555919  0.17658734\n",
      "  -0.6314889   0.09016366  0.62578285  0.74797285 -0.17450722 -0.15867858\n",
      "   0.32925045 -0.6382775  -0.540006    0.5953529  -0.15785612 -0.05199988\n",
      "   0.06875163 -0.00357663  0.9690813  -0.05720938  0.03682116 -0.1433027\n",
      "   0.05391322 -0.16410784 -0.17307395  0.99400085  0.18934825 -0.32135826\n",
      "  -0.96733356  0.4975402  -0.7357518   0.86314666  0.59343874 -0.6136118\n",
      "   0.18079476  0.10829369 -0.13204622  0.40841985 -0.04435366 -0.1517012\n",
      "   0.05547473  0.093516    0.9091913  -0.26429802 -0.90877646 -0.31602627\n",
      "   0.13502143 -0.8979272   0.20333795 -0.32455567 -0.10218439 -0.1936839\n",
      "   0.41150677  0.23894873 -0.12028352 -0.9391256  -0.07081895 -0.13736738\n",
      "   0.8980778   0.05957669 -0.25845426 -0.74437827 -0.6920719  -0.4943596\n",
      "   0.6778858  -0.8667175   0.91204876 -0.94116235  0.20038515  0.9913444\n",
      "   0.26551414 -0.72465104  0.05659474 -0.15613498  0.05524397  0.48381287\n",
      "   0.33590066 -0.88150525 -0.10735054 -0.05805115  0.11249594 -0.0413064\n",
      "   0.47517943  0.49799103  0.12521568 -0.25850853 -0.3865095   0.00908359\n",
      "   0.18953186  0.3852843  -0.20384601  0.01777066  0.02861453 -0.09633587\n",
      "  -0.75393486 -0.10378458 -0.04822416 -0.6613024   0.34269965 -0.9985737\n",
      "  -0.59591043 -0.618798   -0.17173724  0.6518946   0.00370688 -0.288923\n",
      "  -0.5072733   0.625262    0.8651687   0.5486149   0.05657494  0.3495296\n",
      "  -0.53805536 -0.04005996 -0.02958912  0.12111042  0.36860442  0.60000396\n",
      "  -0.07550057  0.99905884 -0.03434957 -0.21019515 -0.8322511   0.12114183\n",
      "  -0.12653548  0.95481753 -0.6174961  -0.85454804  0.17957611 -0.15398663\n",
      "  -0.6043697   0.11220724 -0.05105961 -0.35891953  0.5562825   0.8704863\n",
      "   0.45923147 -0.2696748   0.17833516 -0.17301962 -0.18649028  0.00592981\n",
      "  -0.68842036  0.9616956   0.11505462  0.6919373   0.6618538   0.16436611\n",
      "   0.9074679   0.09314708  0.1474183   0.02089658  0.9936083   0.1244428\n",
      "  -0.83255565  0.53108674 -0.94567835 -0.06227114 -0.84644806  0.11009199\n",
      "  -0.05340135  0.7248389  -0.11741237  0.88097024  0.7152135  -0.00435955\n",
      "   0.37708783  0.69021964  0.22474274 -0.7531546  -0.96483517 -0.9600839\n",
      "  -0.01302185 -0.32867762  0.02864344  0.2108263   0.09487113  0.15576206\n",
      "   0.18841697 -0.99169004  0.8238672   0.271314   -0.59729487  0.90795004\n",
      "  -0.16934456 -0.01424696  0.13125138 -0.95382476 -0.786464   -0.19571951\n",
      "  -0.2131019   0.525387    0.4068786   0.7042273   0.17167458 -0.43852288\n",
      "  -0.06620597  0.6140617  -0.18261091 -0.9699643   0.28133756  0.53571904\n",
      "  -0.745088    0.9000646  -0.64767885 -0.16422677  0.6629224   0.45710832\n",
      "   0.63580203  0.5008738   0.12828776  0.09704527  0.27660918  0.70675516\n",
      "   0.8219711   0.96354496  0.53574437  0.47200814  0.6040072   0.14783478\n",
      "   0.45354536 -0.8533393   0.02336965 -0.27205065  0.12787217  0.12189379\n",
      "  -0.10518031 -0.8197563   0.36705768 -0.09936542  0.18870586 -0.28104421\n",
      "   0.18440925 -0.28229672 -0.12289311 -0.5723531  -0.12050636  0.38706866\n",
      "   0.08751183  0.7976463  -0.0155519   0.03390196 -0.33366013  0.00330458\n",
      "   0.5471101  -0.8356576   0.70411104  0.09182909  0.5623647  -0.5014584\n",
      "  -0.18194686  0.64381546 -0.447028   -0.20694281 -0.10079101 -0.47386017\n",
      "   0.6523225  -0.05109745 -0.24252768 -0.23389268  0.38963735  0.22333278\n",
      "   0.4465224   0.5378232   0.55856085  0.07427666 -0.07870694  0.17741382\n",
      "  -0.04522159 -0.99113035  0.26062724  0.45250213 -0.45851946  0.3792672\n",
      "  -0.6369639   0.2805745  -0.8795036  -0.0680637  -0.22719182 -0.5287232\n",
      "  -0.42864203 -0.04300226  0.23162945  0.46491036 -0.44605947  0.7633177\n",
      "   0.28227022  0.7271288   0.31941828  0.42045397 -0.53386694  0.75248086]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "sentences = \"my name is the first dog\"\n",
    "\n",
    "inputs = tokenizer(sentences, return_tensors='pt')\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    # embeddings = outputs.last_hidden_state\n",
    "    embeddings = outputs.pooler_output\n",
    "\n",
    "out = embeddings.numpy()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
